{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wcq6dWzy1ZR0",
   "metadata": {
    "id": "wcq6dWzy1ZR0"
   },
   "source": [
    "# Payment Date Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778654e",
   "metadata": {
    "id": "2778654e"
   },
   "source": [
    "\n",
    "### Importing related Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304c9e38",
   "metadata": {
    "id": "304c9e38"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _arpack: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17248/3580657592.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    439\u001b[0m \"\"\"\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    398\u001b[0m \"\"\"\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                          \u001b[0mline_search_wolfe2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mline_search\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                          LineSearchWarning)\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_numdiff\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapprox_derivative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetfullargspec_no_self\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMapWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_group_columns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgroup_dense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdsolve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0meigen\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatfuncs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_onenormest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\"\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marpack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlobpcg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marpack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'eigs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eigsh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'svds'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ArpackError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ArpackNoConvergence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_arpack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0marpack_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_arpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtiming\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _arpack: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f5ee",
   "metadata": {
    "id": "8724f5ee"
   },
   "source": [
    "### Store the dataset into the Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415db50a",
   "metadata": {
    "id": "415db50a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e37f05",
   "metadata": {
    "id": "42e37f05"
   },
   "source": [
    "### Check the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc0907",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27cc0907",
    "outputId": "06b76944-02f8-483b-c0e5-00312b4ddedf"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c955d",
   "metadata": {
    "id": "b68c955d"
   },
   "source": [
    "### Check the Detail information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092ec9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e092ec9e",
    "outputId": "12563c8b-5ff1-4db2-c21c-dfcaf7b88679"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f2d0e",
   "metadata": {
    "id": "112f2d0e"
   },
   "source": [
    "### Display All the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416e2fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1416e2fd",
    "outputId": "e2505af2-6534-4a32-f61b-04aff98ed426"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465ed7a",
   "metadata": {
    "id": "d465ed7a"
   },
   "source": [
    "### Describe the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f65e1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "25f65e1b",
    "outputId": "e247c8fa-c27a-48ba-ba7f-fc2bdda1809b"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c8d02",
   "metadata": {
    "id": "0f2c8d02"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Show top 5 records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f876212",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8f876212",
    "outputId": "bb0c96b7-823e-4daf-d4be-17f3fe1bfee1"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b044e4",
   "metadata": {
    "id": "92b044e4"
   },
   "source": [
    "### Display the Null values percentage against every columns (compare to the total number of records)\n",
    "\n",
    "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.12% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7b13d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "24c7b13d",
    "outputId": "712d300d-47df-4088-ad58-8d0f84f00c9f"
   },
   "outputs": [],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,'percent_missing': percent_missing})\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46a98b",
   "metadata": {
    "id": "2c46a98b"
   },
   "source": [
    "### Display Invoice_id and Doc_Id\n",
    "\n",
    "- Note - Many of the would have same invoice_id and doc_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f24bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "038f24bb",
    "outputId": "32a2b9c7-b502-4ce7-901f-c48e5da7f360"
   },
   "outputs": [],
   "source": [
    "df[['invoice_id','doc_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe10a",
   "metadata": {
    "id": "18cfe10a"
   },
   "source": [
    "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
    "\n",
    "- Please note, if they are same, we need to drop them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b40ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "cf5b40ff",
    "outputId": "4689290e-e444-4859-df09-443bb127fc82"
   },
   "outputs": [],
   "source": [
    "df.where((df['baseline_create_date']==df['document_create_date']) & (df['document_create_date']==df['document_create_date.1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110576",
   "metadata": {
    "id": "33110576"
   },
   "source": [
    "#### Please check, Column 'posting_id' is constant columns or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce2664",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecce2664",
    "outputId": "e7438e5b-9f49-4b42-d6fb-f8523f47d8b0"
   },
   "outputs": [],
   "source": [
    "if(df['posting_id'].nunique()==1):\n",
    "  print(True)\n",
    "else:\n",
    "  print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb8daf",
   "metadata": {
    "id": "e5fb8daf"
   },
   "source": [
    "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9956b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8db9956b",
    "outputId": "d9fcd0b5-2bd3-438d-8291-3714cda287f8"
   },
   "outputs": [],
   "source": [
    "no_un=df['isOpen'].nunique()\n",
    "un=df['isOpen'].unique()\n",
    "print(\"Number of unique values: \",no_un)\n",
    "print(\"Unique values are: \")\n",
    "for x in range(len(un)):\n",
    "   print(un[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a11a62",
   "metadata": {
    "id": "45a11a62"
   },
   "source": [
    "### Write the code to drop all the following columns from the dataframe\n",
    "\n",
    "- 'area_business'\n",
    "- \"posting_id\"\n",
    "- \"invoice_id\"\n",
    "- \"document_create_date\"\n",
    "- \"isOpen\"\n",
    "- 'document type' \n",
    "- 'document_create_date.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d85d1",
   "metadata": {
    "id": "270d85d1"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['area_business','posting_id','invoice_id','document_create_date','isOpen','document type','document_create_date.1'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K5LHAM2XVGnk",
   "metadata": {
    "id": "K5LHAM2XVGnk"
   },
   "source": [
    "### Please check from the dataframe whether all the columns are removed or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f7d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef3f7d2b",
    "outputId": "e40833ab-e02f-475b-c359-483e3c92b35f"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc052c7",
   "metadata": {
    "id": "6bc052c7"
   },
   "source": [
    "### Show all the Duplicate rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3c7e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "1ae3c7e4",
    "outputId": "bfac72ef-33db-42a5-8104-986d4c72c9d5"
   },
   "outputs": [],
   "source": [
    "df[df.duplicated()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fab09",
   "metadata": {
    "id": "464fab09"
   },
   "source": [
    "### Display the Number of Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea2397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1ea2397",
    "outputId": "2feddbd7-eebb-4653-bd66-e20f5e6f37e4"
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6718",
   "metadata": {
    "id": "827a6718"
   },
   "source": [
    "### Drop all the Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10151c",
   "metadata": {
    "id": "5d10151c"
   },
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(subset=None,keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1f9b",
   "metadata": {
    "id": "7e5d1f9b"
   },
   "source": [
    "#### Now check for all duplicate rows now\n",
    "\n",
    "- Note - It must be 0 by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9accc9fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9accc9fc",
    "outputId": "ffd25d80-2e8b-49c1-d710-8bde0c55f854"
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0704898",
   "metadata": {
    "id": "d0704898"
   },
   "source": [
    "### Check for the number of Rows and Columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582748a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "582748a8",
    "outputId": "86d2d41a-3667-47f6-fd2c-248968bb5afe"
   },
   "outputs": [],
   "source": [
    "print('Rows: ',df.shape[0])\n",
    "print('Columns: ',df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4o9c5UodWRtl",
   "metadata": {
    "id": "4o9c5UodWRtl"
   },
   "source": [
    "### Find out the total count of null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0612cb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0612cb5",
    "outputId": "2817d1d3-8e71-43b1-a81e-972a7221e672"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdb98b",
   "metadata": {
    "id": "7abdb98b"
   },
   "source": [
    "#Data type Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPfSUSp-WpPj",
   "metadata": {
    "id": "LPfSUSp-WpPj"
   },
   "source": [
    "### Please check the data type of each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c8592",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "689c8592",
    "outputId": "43947395-87ae-4e32-fa10-b27f85758390"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nsem0_3XzOt",
   "metadata": {
    "id": "0nsem0_3XzOt"
   },
   "source": [
    "### Check the datatype format of below columns\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-yyODyW3X6pL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yyODyW3X6pL",
    "outputId": "25ca0560-61f2-4151-d83b-e3dcd3275e8d"
   },
   "outputs": [],
   "source": [
    "print(df['clear_date'].dtype)\n",
    "print(df['posting_date'].dtype)\n",
    "print(df['due_in_date'].dtype)\n",
    "print(df['baseline_create_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf9478",
   "metadata": {
    "id": "11cf9478"
   },
   "source": [
    "### converting date columns into date time formats\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date\n",
    "\n",
    "\n",
    "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c6c71",
   "metadata": {
    "id": "9a8c6c71"
   },
   "outputs": [],
   "source": [
    "df['clear_date'] = pd.to_datetime(df['clear_date'])\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'])\n",
    "df['due_in_date'] = pd.to_datetime(df['due_in_date'], format='%Y%m%d')\n",
    "df['baseline_create_date'] = pd.to_datetime(df['baseline_create_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adq0wSIYSCS",
   "metadata": {
    "id": "7adq0wSIYSCS"
   },
   "source": [
    "### Please check the datatype of all the columns after conversion of the above 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd028c61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd028c61",
    "outputId": "2bc8d61f-6e1d-4b92-bd51-0145ffaeaf99"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9882fa",
   "metadata": {
    "id": "8c9882fa"
   },
   "source": [
    "#### the invoice_currency column contains two different categories, USD and CAD\n",
    "\n",
    "- Please do a count of each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72085397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72085397",
    "outputId": "b77578cd-f703-484e-ccfc-07e1300f14d7"
   },
   "outputs": [],
   "source": [
    "df['invoice_currency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe26ee",
   "metadata": {
    "id": "6cbe26ee"
   },
   "source": [
    "#### display the \"total_open_amount\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49f2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c49f2ab",
    "outputId": "8a4943b2-c098-4ace-d187-5982cbb84efa"
   },
   "outputs": [],
   "source": [
    "df['total_open_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df899966",
   "metadata": {
    "id": "df899966"
   },
   "source": [
    "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
    "\n",
    "- 1 CAD = 0.7 USD\n",
    "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2f1c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8eb2f1c5",
    "outputId": "3bc9d385-7baf-498a-efcd-a2980937d444"
   },
   "outputs": [],
   "source": [
    "df['converted_usd'] = np.where(df['invoice_currency']=='CAD', 0.7*df['total_open_amount'], df['total_open_amount'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ef1d",
   "metadata": {
    "id": "f9f6ef1d"
   },
   "source": [
    "### Display the new \"converted_usd\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1a178",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fc1a178",
    "outputId": "95cea9cb-de4a-4dee-f1d6-d3c498c8774a"
   },
   "outputs": [],
   "source": [
    "df['converted_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XLXX17kayuy",
   "metadata": {
    "id": "6XLXX17kayuy"
   },
   "source": [
    "### Display year wise total number of record \n",
    "\n",
    "- Note -  use \"buisness_year\" column for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9f6ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00c9f6ee",
    "outputId": "c405695f-577d-4423-f5d4-52e0a3f09232"
   },
   "outputs": [],
   "source": [
    "df['buisness_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35904",
   "metadata": {
    "id": "05c35904"
   },
   "source": [
    "### Write the code to delete the following columns \n",
    "\n",
    "- 'invoice_currency'\n",
    "- 'total_open_amount', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac28aa5",
   "metadata": {
    "id": "4ac28aa5"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['invoice_currency','total_open_amount'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bDBJ_Kvwc086",
   "metadata": {
    "id": "bDBJ_Kvwc086"
   },
   "source": [
    "### Write a code to check the number of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea360a8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea360a8c",
    "outputId": "9d83b1a1-8783-4071-b980-7d25a5ab7f6a"
   },
   "outputs": [],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f63655",
   "metadata": {
    "id": "b8f63655"
   },
   "source": [
    "# Splitting the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f749d",
   "metadata": {
    "id": "a00f749d"
   },
   "source": [
    "### Look for all columns containing null value\n",
    "\n",
    "- Note - Output expected is only one column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c801e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "148c801e",
    "outputId": "5b42e7e6-db3a-48ea-e62b-44520f9fa528"
   },
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094a290",
   "metadata": {
    "id": "a094a290"
   },
   "source": [
    "#### Find out the number of null values from the column that you got from the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30bfb113",
    "outputId": "ee53a50b-cb5b-44ee-aba9-e794b601ff5b"
   },
   "outputs": [],
   "source": [
    "df['clear_date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d939b",
   "metadata": {
    "id": "7f6d939b"
   },
   "source": [
    "### On basis of the above column we are spliting data into dataset\n",
    "\n",
    "- First dataframe (refer that as maindata) only containing the rows, that have NO NULL data in that column ( This is going to be our train dataset ) \n",
    "- Second dataframe (refer that as nulldata) that contains the columns, that have Null data in that column ( This is going to be our test dataset ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8764c33",
   "metadata": {
    "id": "c8764c33"
   },
   "outputs": [],
   "source": [
    "maindata = df[df['clear_date'].notnull()]\n",
    "nulldata = df[df['clear_date'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3P8riRBHd_r6",
   "metadata": {
    "id": "3P8riRBHd_r6"
   },
   "source": [
    "### Check the number of Rows and Columns for both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693a464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0693a464",
    "outputId": "10c0680a-1e8f-4e17-b678-70acd003817e"
   },
   "outputs": [],
   "source": [
    "print('Number of rows of Train dataset',nulldata.shape[0])\n",
    "print('Number of rows of Test dataset',maindata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86bc74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f86bc74",
    "outputId": "8ae2fe67-ce05-49b5-f43a-949ef4d779a3"
   },
   "outputs": [],
   "source": [
    "print('Number of columns of Train dataset',nulldata.shape[1])\n",
    "print('Number of columns of Test dataset',maindata.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747165d",
   "metadata": {
    "id": "0747165d"
   },
   "source": [
    "### Display the 5 records from maindata and nulldata dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2ec36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "dec2ec36",
    "outputId": "67df8841-1538-41c0-9059-96ec50fbca18"
   },
   "outputs": [],
   "source": [
    "print('5 records from the maindata dataframe:')\n",
    "maindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2d68a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eee2d68a",
    "outputId": "b7ae7f4f-ce19-4050-8de5-b399291345f7"
   },
   "outputs": [],
   "source": [
    "print('5 records from the nulldata dataframe:')\n",
    "nulldata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6746",
   "metadata": {
    "id": "24aa6746"
   },
   "source": [
    "## Considering the **maindata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c4aa7",
   "metadata": {
    "id": "f92c4aa7"
   },
   "source": [
    "#### Generate a new column \"Delay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
    "- Formula - Delay = clear_date - due_in_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeceb9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8eeceb9c",
    "outputId": "4103feb7-2743-4686-91c6-dce0ff0aa88c"
   },
   "outputs": [],
   "source": [
    "maindata['Delay'] = maindata['clear_date']-maindata['due_in_date']\n",
    "maindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482144e",
   "metadata": {
    "id": "f482144e"
   },
   "source": [
    "### Generate a new column \"avgdelay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
    "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
    "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "- Display the new \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d2f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d18d2f8d",
    "outputId": "58b2a560-45a4-47cb-a945-88a487ff2f94"
   },
   "outputs": [],
   "source": [
    "avgdelay=maindata.groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "avgdelay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b995e8",
   "metadata": {
    "id": "64b995e8"
   },
   "source": [
    "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
    "\n",
    " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1f3d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e1f3d9",
    "outputId": "ceaf7394-afa8-42f2-85c8-9fcbd2285fc8"
   },
   "outputs": [],
   "source": [
    "maindata['avg_delay'] = maindata['name_customer'].map(avgdelay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d332525",
   "metadata": {
    "id": "1d332525"
   },
   "source": [
    "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
    "\n",
    "- Days_format :  17 days 00:00:00\n",
    "- Format in seconds : 1641600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1041e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5f1041e",
    "outputId": "fbde491e-9c3c-46ae-dd81-638f08f8bb96"
   },
   "outputs": [],
   "source": [
    "maindata['avg_delay']=maindata['avg_delay']/np.timedelta64(1,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvgtHSsx_O-n",
   "metadata": {
    "id": "OvgtHSsx_O-n"
   },
   "source": [
    "### Display the maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca9c45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "97ca9c45",
    "outputId": "e8619c0d-131f-4f8f-fc6b-b393a75e9a65"
   },
   "outputs": [],
   "source": [
    "maindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24c7bb",
   "metadata": {
    "id": "ae24c7bb"
   },
   "source": [
    "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
    "\n",
    "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a61ab9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "78a61ab9",
    "outputId": "7f4eeffb-6901-4187-cd33-0aac1ab191bc"
   },
   "outputs": [],
   "source": [
    "maindata=maindata.drop(['clear_date','Delay'],axis=1)\n",
    "maindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae724bfc",
   "metadata": {
    "id": "ae724bfc"
   },
   "source": [
    "# Splitting of Train and the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f0264",
   "metadata": {
    "id": "cb6f0264"
   },
   "source": [
    "### You need to split the \"maindata\" columns into X and y dataframe\n",
    "\n",
    "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
    "\n",
    "- X is going to hold the source fields and y will be going to hold the target fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab29ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "75ab29ab",
    "outputId": "d22a48cd-c144-455c-e874-f53f3a9c97a3"
   },
   "outputs": [],
   "source": [
    "y=maindata[['avg_delay']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412c62b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6412c62b",
    "outputId": "c214c63a-6f5f-45d4-8c5e-0452aabfc76c"
   },
   "outputs": [],
   "source": [
    "X = maindata.drop(['avg_delay'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2942bf",
   "metadata": {
    "id": "1c2942bf"
   },
   "source": [
    "#### You are expected to split both the dataframes into train and test format in 60:40 ratio \n",
    "\n",
    "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92160a5",
   "metadata": {
    "id": "d92160a5"
   },
   "outputs": [],
   "source": [
    "X_train, X_loc_test,y_train, y_loc_test = train_test_split( X,y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p4OME62pDufR",
   "metadata": {
    "id": "p4OME62pDufR"
   },
   "source": [
    "### Please check for the number of rows and columns of all the new dataframes (all 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48328d0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48328d0a",
    "outputId": "12284f76-0193-40c5-a4e9-1e9ef8fe2538"
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_loc_test.shape,y_train.shape,y_loc_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68ed71",
   "metadata": {
    "id": "4a68ed71"
   },
   "source": [
    "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
    "\n",
    "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c62f2",
   "metadata": {
    "id": "b56c62f2"
   },
   "outputs": [],
   "source": [
    "X_val, X_test,y_val, y_test = train_test_split( X_loc_test,y_loc_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJTSAskvERH1",
   "metadata": {
    "id": "bJTSAskvERH1"
   },
   "source": [
    "### Please check for the number of rows and columns of all the 4 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d7564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "845d7564",
    "outputId": "94df54b5-e21f-43a3-dcda-6db803f1abc5"
   },
   "outputs": [],
   "source": [
    "print('X_val shape: ',X_val.shape)\n",
    "print('X_test shape: ',X_test.shape)\n",
    "print('y_val shape: ', y_val.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fa872",
   "metadata": {
    "id": "110fa872"
   },
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8fe0f",
   "metadata": {
    "id": "ffc8fe0f"
   },
   "source": [
    "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
    "\n",
    "- Note - You are expected to make a distribution plot for the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bf8ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ba2bf8ed",
    "outputId": "92a878ca-ca0b-4596-d752-a0dbc95dee09"
   },
   "outputs": [],
   "source": [
    "sns.distplot(maindata['avg_delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e323a3",
   "metadata": {
    "id": "d0e323a3"
   },
   "source": [
    "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
    "\n",
    "### Need to store the outcome into a new dataframe \n",
    "\n",
    "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "f7acf0ee",
    "outputId": "e6fddd95-d0d0-4305-dff5-de8e89ee454c"
   },
   "outputs": [],
   "source": [
    "X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cA43bFffFt6i",
   "metadata": {
    "id": "cA43bFffFt6i"
   },
   "source": [
    "### You can make another distribution plot of the \"doc_id\" column from x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576bf33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "9576bf33",
    "outputId": "f2e05e93-d2a8-4166-c9b1-d3d4c55ce713"
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train['doc_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2c44f",
   "metadata": {
    "id": "fba2c44f"
   },
   "source": [
    "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecec77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4fecec77",
    "outputId": "00d3a74b-d947-4459-ebde-e7e8fc13026b"
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train['buisness_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qr1jGhfOKjnw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qr1jGhfOKjnw",
    "outputId": "21be59d7-82b0-45e9-90e5-c53c39e67efa"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='buisness_year',y='doc_id',data=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fbcc9",
   "metadata": {
    "id": "968fbcc9"
   },
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbh6CyGqH3XE",
   "metadata": {
    "id": "jbh6CyGqH3XE"
   },
   "source": [
    "### Display and describe the X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcf307",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "e6bcf307",
    "outputId": "324fc794-a2f0-4204-a61f-cb6f09e2c2a6"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "08ccc819",
    "outputId": "a67fc27d-3c3e-4c85-ef02-270df6586092"
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7ac8b",
   "metadata": {
    "id": "abd7ac8b"
   },
   "source": [
    "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
    "\n",
    "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
    "- Note - Please fill in the blanks (two) to complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c223545",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c223545",
    "outputId": "05c96ce3-5ce8-4b30-e926-76ba416cd1f3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_coder = LabelEncoder()\n",
    "business_coder.fit(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f7d9c",
   "metadata": {
    "id": "f86f7d9c"
   },
   "source": [
    "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
    "\n",
    "- Note - For Training set you are expected to use fit_trainsform()\n",
    "- Note - For Test set you are expected to use the trainsform()\n",
    "- Note - For Validation set you are expected to use the trainsform()\n",
    "\n",
    "\n",
    "- Partial code is provided, please fill in the blanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269c307",
   "metadata": {
    "id": "4269c307"
   },
   "outputs": [],
   "source": [
    "X_train['business_code_enc'] = business_coder.fit_transform(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53712",
   "metadata": {
    "id": "70a53712"
   },
   "outputs": [],
   "source": [
    "X_val['business_code_enc'] = business_coder.transform(X_val['business_code'])\n",
    "X_test['business_code_enc'] = business_coder.transform(X_test['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gdNYxTkqNfmz",
   "metadata": {
    "id": "gdNYxTkqNfmz"
   },
   "source": [
    "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196a002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "1196a002",
    "outputId": "37ba1e6d-331f-44f7-dbcc-b066c5b32ebc"
   },
   "outputs": [],
   "source": [
    "X_train[['business_code','business_code_enc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11477224",
   "metadata": {
    "id": "11477224"
   },
   "source": [
    "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
    "\n",
    "- Note - Fill in the blank to complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052868a",
   "metadata": {
    "id": "1052868a"
   },
   "outputs": [],
   "source": [
    "def custom(col ,traindf = X_train,valdf = X_val,testdf = X_test):\n",
    "    traindf.drop(col, axis =1,inplace=True)\n",
    "    valdf.drop(col,axis=1 , inplace=True)\n",
    "    testdf.drop(col,axis=1 , inplace=True)\n",
    "\n",
    "    return traindf,valdf ,testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rI--ZuMbNLne",
   "metadata": {
    "id": "rI--ZuMbNLne"
   },
   "source": [
    "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
    "\n",
    "- Note = Fill in the blank to complete the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f955c",
   "metadata": {
    "id": "1a0f955c"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,X_test = custom(['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5b27e",
   "metadata": {
    "id": "28b5b27e"
   },
   "source": [
    "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
    "\n",
    "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd129e",
   "metadata": {
    "id": "85dd129e"
   },
   "outputs": [],
   "source": [
    "X_train['cust_number'] = X_train['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_test['cust_number'] = X_test['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_val['cust_number'] = X_val['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8vA-zmdPnJ8",
   "metadata": {
    "id": "U8vA-zmdPnJ8"
   },
   "source": [
    "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
    "\n",
    "#### This will fit the encoder for all the unique values and introduce unknown value\n",
    "\n",
    "- Note - Keep this code as it is, we will be using this later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f48ba",
   "metadata": {
    "id": "151f48ba"
   },
   "outputs": [],
   "source": [
    "#For encoding unseen labels\n",
    "class EncoderExt(object):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    def fit(self, data_list):\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        return self\n",
    "    def transform(self, data_list):\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c64e6",
   "metadata": {
    "id": "254c64e6"
   },
   "source": [
    "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b17eff",
   "metadata": {
    "id": "62b17eff"
   },
   "outputs": [],
   "source": [
    "label_encoder = EncoderExt()\n",
    "label_encoder.fit(X_train['name_customer'])\n",
    "X_train['name_customer_enc']=label_encoder.transform(X_train['name_customer'])\n",
    "X_val['name_customer_enc']=label_encoder.transform(X_val['name_customer'])\n",
    "X_test['name_customer_enc']=label_encoder.transform(X_test['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mK7LMoy2QZhy",
   "metadata": {
    "id": "mK7LMoy2QZhy"
   },
   "source": [
    "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85f1c0",
   "metadata": {
    "id": "ef85f1c0"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa09d22",
   "metadata": {
    "id": "3aa09d22"
   },
   "source": [
    "### Using Label Encoder for the \"cust_payment_terms\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab642",
   "metadata": {
    "id": "6f9ab642"
   },
   "outputs": [],
   "source": [
    "label_encoder1 = EncoderExt()\n",
    "label_encoder1.fit(X_train['cust_payment_terms'])\n",
    "X_train['cust_payment_terms_enc']=label_encoder1.transform(X_train['cust_payment_terms'])\n",
    "X_val['cust_payment_terms_enc']=label_encoder1.transform(X_val['cust_payment_terms'])\n",
    "X_test['cust_payment_terms_enc']=label_encoder1.transform(X_test['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9a7c2",
   "metadata": {
    "id": "55f9a7c2"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f42b",
   "metadata": {
    "id": "0788f42b"
   },
   "source": [
    "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
    "\n",
    "- Note - You are expected yo use dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a316",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc79a316",
    "outputId": "28896db2-0f6a-429c-ccbb-3def9774a9a3"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33242d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b33242d8",
    "outputId": "70b0828a-577a-419b-b996-e5f0bc2ff83d"
   },
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4da71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bd4da71",
    "outputId": "d2d911b3-2cb2-4db2-e444-cb4cd6447154"
   },
   "outputs": [],
   "source": [
    "X_val.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LVfvuPiWPeMB",
   "metadata": {
    "id": "LVfvuPiWPeMB"
   },
   "source": [
    "### From the above output you can notice their are multiple date columns with datetime format\n",
    "\n",
    "### In order to pass it into our model, we need to convert it into float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d344db9",
   "metadata": {
    "id": "9d344db9"
   },
   "source": [
    "### You need to extract day, month and year from the \"posting_date\" column \n",
    "\n",
    "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cdfd6",
   "metadata": {
    "id": "6e3cdfd6"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_postingdate'] = X_train['posting_date'].dt.day\n",
    "X_train['month_of_postingdate'] = X_train['posting_date'].dt.month\n",
    "X_train['year_of_postingdate'] = X_train['posting_date'].dt.year\n",
    "\n",
    "X_val['day_of_postingdate'] = X_val['posting_date'].dt.day\n",
    "X_val['month_of_postingdate'] = X_val['posting_date'].dt.month\n",
    "X_val['year_of_postingdate'] = X_val['posting_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_postingdate'] = X_test['posting_date'].dt.day\n",
    "X_test['month_of_postingdate'] = X_test['posting_date'].dt.month\n",
    "X_test['year_of_postingdate'] = X_test['posting_date'].dt.year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GyI-F853Rxa7",
   "metadata": {
    "id": "GyI-F853Rxa7"
   },
   "source": [
    "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQHtQkrnRx_V",
   "metadata": {
    "id": "FQHtQkrnRx_V"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['posting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GMnCaEcKReSw",
   "metadata": {
    "id": "GMnCaEcKReSw"
   },
   "source": [
    "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
    "\n",
    "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "- Note - Do as it is been shown in the previous two code boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d83d0",
   "metadata": {
    "id": "ee4d83d0"
   },
   "source": [
    "### Extracting Day, Month, Year for 'baseline_create_date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b240e1",
   "metadata": {
    "id": "32b240e1"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_createdate'] = X_train['baseline_create_date'].dt.day\n",
    "X_train['month_of_createdate'] = X_train['baseline_create_date'].dt.month\n",
    "X_train['year_of_createdate'] = X_train['baseline_create_date'].dt.year\n",
    "\n",
    "X_val['day_of_createdate'] = X_val['baseline_create_date'].dt.day\n",
    "X_val['month_of_createdate'] = X_val['baseline_create_date'].dt.month\n",
    "X_val['year_of_createdate'] = X_val['baseline_create_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_createdate'] = X_test['baseline_create_date'].dt.day\n",
    "X_test['month_of_createdate'] = X_test['baseline_create_date'].dt.month\n",
    "X_test['year_of_createdate'] = X_test['baseline_create_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFgwkS5rSDDs",
   "metadata": {
    "id": "cFgwkS5rSDDs"
   },
   "source": [
    "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGYa2BEQSDg3",
   "metadata": {
    "id": "RGYa2BEQSDg3"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['baseline_create_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7a0df",
   "metadata": {
    "id": "77c7a0df"
   },
   "source": [
    "### You need to extract day, month and year from the \"due_in_date\" column \n",
    "\n",
    "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
    "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
    "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "- Note - Do as it is been shown in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745547",
   "metadata": {
    "id": "5c745547"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_due'] = X_train['due_in_date'].dt.day\n",
    "X_train['month_of_due'] = X_train['due_in_date'].dt.month\n",
    "X_train['year_of_due'] = X_train['due_in_date'].dt.year\n",
    "\n",
    "X_val['day_of_due'] = X_val['due_in_date'].dt.day\n",
    "X_val['month_of_due'] = X_val['due_in_date'].dt.month\n",
    "X_val['year_of_due'] = X_val['due_in_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_due'] = X_test['due_in_date'].dt.day\n",
    "X_test['month_of_due'] = X_test['due_in_date'].dt.month\n",
    "X_test['year_of_due'] = X_test['due_in_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FYLLzulGSvRd",
   "metadata": {
    "id": "FYLLzulGSvRd"
   },
   "source": [
    "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-s6QuY9Svrh",
   "metadata": {
    "id": "1-s6QuY9Svrh"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['due_in_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5d052",
   "metadata": {
    "id": "1ae5d052"
   },
   "source": [
    "### Check for the datatypes for train, test and validation set again\n",
    "\n",
    "- Note - all the data type should be in either int64 or float64 format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9d828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "aee9d828",
    "outputId": "a4c519d1-ba2f-49e5-a595-6d043c925ea7"
   },
   "outputs": [],
   "source": [
    "display(X_train.dtypes)\n",
    "display(X_test.dtypes)\n",
    "display(X_val.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65810f55",
   "metadata": {
    "id": "65810f55"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1ad9f",
   "metadata": {
    "id": "4bb1ad9f"
   },
   "source": [
    "### Filter Method\n",
    "\n",
    "- Calling the VarianceThreshold Function \n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882509f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e882509f",
    "outputId": "5b42b00d-9fdc-4e81-a30f-734d5f40b207"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9531H3jR-W2",
   "metadata": {
    "id": "V9531H3jR-W2"
   },
   "source": [
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c12e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c77c12e1",
    "outputId": "468945af-1b3b-4a95-c3f4-1a74bf114d77"
   },
   "outputs": [],
   "source": [
    "constant_columns = [column for column in X_train.columns\n",
    "                    if column not in X_train.columns[constant_filter.get_support()]]\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b8610",
   "metadata": {
    "id": "6d9b8610"
   },
   "source": [
    "- transpose the feature matrice\n",
    "- print the number of duplicated features\n",
    "- select the duplicated features columns names\n",
    "\n",
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7db95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fb7db95",
    "outputId": "2f6f53a7-842e-4aed-9721-f614640b98a8"
   },
   "outputs": [],
   "source": [
    "x_train_T = X_train.T\n",
    "print(x_train_T.duplicated().sum())\n",
    "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa831",
   "metadata": {
    "id": "510fa831"
   },
   "source": [
    "### Filtering depending upon correlation matrix value\n",
    "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
    "\n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731abc",
   "metadata": {
    "id": "67731abc"
   },
   "outputs": [],
   "source": [
    "def handling_correlation(X_train,threshold=0.8):\n",
    "    corr_features = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix .columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "    return list(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JaE_6qVgSXl3",
   "metadata": {
    "id": "JaE_6qVgSXl3"
   },
   "source": [
    "- Note : Here we are trying to find out the relevant fields, from X_train\n",
    "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d1a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd91d1a2",
    "outputId": "d0693fa0-084b-48d9-c7f1-f0772bb5b905"
   },
   "outputs": [],
   "source": [
    "train=X_train.copy()\n",
    "handling_correlation(train.copy(),0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154da511",
   "metadata": {
    "id": "154da511"
   },
   "source": [
    "### Heatmap for X_train\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f2fe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2e8f2fe4",
    "outputId": "348067e1-e9da-4c2f-fcc7-deaeacca6530"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=20)\n",
    "sns.heatmap(X_train.merge(y_train , on = X_train.index ).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap='gist_rainbow_r', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0d745",
   "metadata": {
    "id": "e3b0d745"
   },
   "source": [
    "#### Calling variance threshold for threshold value = 0.8\n",
    "\n",
    "- Note -  Fill in the blanks to call the appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2080f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9b2080f",
    "outputId": "040a8859-399d-4392-cf1b-8cc18f651392"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(0.8)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8c3dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cb8c3dc",
    "outputId": "f9d7b74b-7689-4b2b-a397-c72622d89a4a"
   },
   "outputs": [],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62633a84",
   "metadata": {
    "id": "62633a84"
   },
   "source": [
    "### Features columns are \n",
    "- 'year_of_createdate' \n",
    "- 'year_of_due'\n",
    "- 'day_of_createdate'\n",
    "- 'year_of_postingdate'\n",
    "- 'month_of_due'\n",
    "- 'month_of_createdate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f1ad0",
   "metadata": {
    "id": "651f1ad0"
   },
   "source": [
    "# Modelling \n",
    "\n",
    "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression\n",
    "- Support Vector Regression\n",
    "- Extreme Gradient Boost Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PicEhSuUUOkt",
   "metadata": {
    "id": "PicEhSuUUOkt"
   },
   "source": [
    "### You need to make different blank list for different evaluation matrix \n",
    "\n",
    "- MSE\n",
    "- R2\n",
    "- Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e12b0",
   "metadata": {
    "id": "701e12b0"
   },
   "outputs": [],
   "source": [
    "MSE_Score = []\n",
    "R2_Score = []\n",
    "Algorithm = []\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29310119",
   "metadata": {
    "id": "29310119"
   },
   "source": [
    "### You need to start with the baseline model Linear Regression\n",
    "\n",
    "- Step 1 : Call the Linear Regression from sklearn library\n",
    "- Step 2 : make an object of Linear Regression \n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdea395",
   "metadata": {
    "id": "6bdea395"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Algorithm.append('LinearRegression')\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G02cpnBhXJ14",
   "metadata": {
    "id": "G02cpnBhXJ14"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69ca19",
   "metadata": {
    "id": "0f69ca19"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsmScbHjYMv1",
   "metadata": {
    "id": "CsmScbHjYMv1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe653295",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe653295",
    "outputId": "f5e514e6-8620-4c91-8560-9007adcf05bd"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LokxV2LGYUVh",
   "metadata": {
    "id": "LokxV2LGYUVh"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c405bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c405bd3",
    "outputId": "4489a2f5-f13c-4dff-e3eb-afa24350836e"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e65c86",
   "metadata": {
    "id": "b0e65c86"
   },
   "source": [
    "### You need to start with the baseline model Support Vector Regression\n",
    "\n",
    "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
    "- Step 2 : make an object of SVR\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5de08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccb5de08",
    "outputId": "751d9e57-995e-41fc-b344-d81908255f7b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.svm import SVR\n",
    "Algorithm.append('SupportVectorRegression')\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zz9kcrViYt7e",
   "metadata": {
    "id": "zz9kcrViYt7e"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9db76",
   "metadata": {
    "id": "5bb9db76"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0YAxd8N9Y0hJ",
   "metadata": {
    "id": "0YAxd8N9Y0hJ"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee71b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6ee71b1",
    "outputId": "961ed004-c812-471b-8bab-fb77cd40460a"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eGcqS5EcY4BI",
   "metadata": {
    "id": "eGcqS5EcY4BI"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72c1ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa72c1ec",
    "outputId": "4b859ef1-39e0-4782-b312-488be04ac431"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad18bb3",
   "metadata": {
    "id": "dad18bb3"
   },
   "source": [
    "### Your next model would be Decision Tree Regression\n",
    "\n",
    "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
    "- Step 2 : make an object of Decision Tree\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a51eb",
   "metadata": {
    "id": "1b6a51eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Algorithm.append('DecisionTreeRegressor')\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AOzfgfeOZo3F",
   "metadata": {
    "id": "AOzfgfeOZo3F"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6983",
   "metadata": {
    "id": "776e6983"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eI6d49DQZrhW",
   "metadata": {
    "id": "eI6d49DQZrhW"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb55c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155fb55c",
    "outputId": "7228b9a8-8172-4d5d-bd37-7e9806534614"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbGXvBLQZw5E",
   "metadata": {
    "id": "sbGXvBLQZw5E"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d515",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d74d515",
    "outputId": "6b5ddbff-795c-4ee3-8ac2-1916f1c012cf"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9979b",
   "metadata": {
    "id": "4ae9979b"
   },
   "source": [
    "### Your next model would be Random Forest Regression\n",
    "\n",
    "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
    "- Step 2 : make an object of Random Forest\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e476a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a69e476a",
    "outputId": "7ccaa18a-6e0a-4077-fb5c-0074bb39e710"
   },
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "Algorithm.append('RandomForestRegressor')\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XNcEJF-6anof",
   "metadata": {
    "id": "XNcEJF-6anof"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f63f4",
   "metadata": {
    "id": "826f63f4"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yMbyr9V4ati1",
   "metadata": {
    "id": "yMbyr9V4ati1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9fb54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55b9fb54",
    "outputId": "0f0d08fc-9221-4dbc-ab70-dc6c75f69dc0"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiBawcCsaw_Z",
   "metadata": {
    "id": "tiBawcCsaw_Z"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c13e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8277c13e",
    "outputId": "d367cc92-b69a-45e6-8790-1d942f54f1ee"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b21881",
   "metadata": {
    "id": "e6b21881"
   },
   "source": [
    "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
    "\n",
    "- Step 1 : Call the XGBoost Regressor from xgb library\n",
    "- Step 2 : make an object of Xgboost\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
    "- Note -  No need to change the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a38ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "705a38ec",
    "outputId": "3a4425e9-8ef5-4b26-f71c-2fb41889e143"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "Algorithm.append('XGB Regressor')\n",
    "regressor = xgb.XGBRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ierNZkb9bQDD",
   "metadata": {
    "id": "ierNZkb9bQDD"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a9d2f",
   "metadata": {
    "id": "507a9d2f"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84UZ2ojsbWaH",
   "metadata": {
    "id": "84UZ2ojsbWaH"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ac250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e78ac250",
    "outputId": "febd83ae-460a-4f5a-cd88-88fd5a261c90"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9FJFyaVbbbAH",
   "metadata": {
    "id": "9FJFyaVbbbAH"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765ba35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f765ba35",
    "outputId": "e5c9e0d5-82c9-4160-f214-7d444ff04b23"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iiyuHKhlMbUC",
   "metadata": {
    "id": "iiyuHKhlMbUC"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71bc90f",
   "metadata": {
    "id": "a71bc90f"
   },
   "source": [
    "## You need to make the comparison list into a comparison dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5159a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "ff5159a7",
    "outputId": "bbc9cc33-e284-44db-f74f-940ba0d7615b"
   },
   "outputs": [],
   "source": [
    "comparison=pd.DataFrame([MSE_Score,R2_Score],columns=Algorithm)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e61c60",
   "metadata": {
    "id": "62e61c60"
   },
   "source": [
    "## Now from the Comparison table, you need to choose the best fit model\n",
    "\n",
    "- Step 1 - Fit X_train and y_train inside the model \n",
    "- Step 2 - Predict the X_test dataset\n",
    "- Step 3 - Predict the X_val dataset\n",
    "\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07c258",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e07c258",
    "outputId": "34d6fc62-ad2d-434d-b557-edb7fbf27631"
   },
   "outputs": [],
   "source": [
    "regressorfinal = xgb.XGBRegressor()\n",
    "regressorfinal.fit(X_train, y_train)\n",
    "predictedfinal = regressorfinal.predict(X_test)\n",
    "predict_testfinal = regressorfinal.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4df6c4",
   "metadata": {
    "id": "8e4df6c4"
   },
   "source": [
    "### Calculate the Mean Square Error for test dataset\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb466d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fb466d0",
    "outputId": "628aca90-51b1-493f-f673-b47db0d9f4db"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,predictedfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27f87f",
   "metadata": {
    "id": "ce27f87f"
   },
   "source": [
    "### Calculate the mean Square Error for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47978ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b47978ea",
    "outputId": "7729175b-21b3-4487-be3e-f55709862fd9"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30014dbd",
   "metadata": {
    "id": "30014dbd"
   },
   "source": [
    "### Calculate the R2 score for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a162737",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a162737",
    "outputId": "be956e49-c5d1-4d4d-8809-ca8cc5b13457"
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9853b0",
   "metadata": {
    "id": "1c9853b0"
   },
   "source": [
    "### Calculate the R2 score for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dc77c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a6dc77c",
    "outputId": "d8fdbea4-8022-4c27-b158-000607c604e9"
   },
   "outputs": [],
   "source": [
    "r2_score(y_val, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499522d9",
   "metadata": {
    "id": "499522d9"
   },
   "source": [
    "### Calculate the Accuracy for train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f1ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a4f1ce8",
    "outputId": "9f163d5f-09cf-4bbe-e904-800dccc693c8"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_train,y_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1c921",
   "metadata": {
    "id": "12a1c921"
   },
   "source": [
    "### Calculate the accuracy for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2579b4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2579b4f",
    "outputId": "650dde62-602a-4e7f-b989-99815ad76b4b"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_val,y_val)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b82e84",
   "metadata": {
    "id": "79b82e84"
   },
   "source": [
    "### Calculate the accuracy for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e6431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f09e6431",
    "outputId": "672d6f8a-48f3-42dc-8c08-44dd3463de59"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_test,y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488a5d9",
   "metadata": {
    "id": "9488a5d9"
   },
   "source": [
    "## Specify the reason behind choosing your machine learning model \n",
    "\n",
    "- Note : Provide your answer as a text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6519",
   "metadata": {
    "id": "387a6519"
   },
   "source": [
    "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
    "\n",
    "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
    "\n",
    "- Step 1 : Label Encoding \n",
    "- Step 2 : Day, Month and Year extraction \n",
    "- Step 3 : Change all the column data type into int64 or float64\n",
    "- Step 4 : Need to drop the useless columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7JuxAkdiAdI",
   "metadata": {
    "id": "I7JuxAkdiAdI"
   },
   "source": [
    "### Display the Nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a51d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "6d6a51d2",
    "outputId": "4046060e-f1fc-4fc5-fdad-2bf40565f008"
   },
   "outputs": [],
   "source": [
    "nulldata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vamx5xqtiHCH",
   "metadata": {
    "id": "Vamx5xqtiHCH"
   },
   "source": [
    "### Check for the number of rows and columns in the nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de1092",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59de1092",
    "outputId": "420debbc-410e-4a03-8d95-25bf33eb3736"
   },
   "outputs": [],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxzHNbBjpqXL",
   "metadata": {
    "id": "BxzHNbBjpqXL"
   },
   "source": [
    "### Check the Description and Information of the nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294d29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6294d29",
    "outputId": "56f8db84-4d31-4084-c35c-83ee4bf78fe8"
   },
   "outputs": [],
   "source": [
    "print(nulldata.describe)\n",
    "print(nulldata.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe860d94",
   "metadata": {
    "id": "fe860d94"
   },
   "source": [
    "### Storing the Nulldata into a different dataset \n",
    "# for BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16352034",
   "metadata": {
    "id": "16352034"
   },
   "outputs": [],
   "source": [
    "nulldata1=nulldata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f35b8c",
   "metadata": {
    "id": "00f35b8c"
   },
   "source": [
    "### Call the Label Encoder for Nulldata\n",
    "\n",
    "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf04b17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baf04b17",
    "outputId": "c57f3f2f-4215-403c-f1d6-cd216efaa854"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_codern = LabelEncoder()\n",
    "business_codern.fit(nulldata['business_code'])\n",
    "nulldata['business_code_enc'] = business_codern.transform(nulldata['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZCPBK9karIR-",
   "metadata": {
    "id": "ZCPBK9karIR-"
   },
   "source": [
    "### Now you need to manually replacing str values with numbers\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64924be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c64924be",
    "outputId": "5f2b0148-79d4-4a82-ac4a-c8f7ef34fbfd"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_number'] = nulldata['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55f5f6",
   "metadata": {
    "id": "9a55f5f6"
   },
   "source": [
    "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
    "\n",
    "\n",
    "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
    "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
    "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
    "\n",
    "\n",
    "\n",
    "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
    "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
    "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
    "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
    "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
    "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
    "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed To use - \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166fbe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4166fbe4",
    "outputId": "628454da-9c6c-4841-c81f-3ef460cac1cd"
   },
   "outputs": [],
   "source": [
    "nulldata['day_of_cleardate'] = nulldata['clear_date'].dt.day\n",
    "nulldata['month_of_cleardate'] = nulldata['clear_date'].dt.month\n",
    "nulldata['year_of_cleardate'] = nulldata['clear_date'].dt.year\n",
    "\n",
    "nulldata['day_of_postingdate'] = nulldata['posting_date'].dt.day\n",
    "nulldata['month_of_postingdate'] = nulldata['posting_date'].dt.month\n",
    "nulldata['year_of_postingdate'] = nulldata['posting_date'].dt.year\n",
    "\n",
    "nulldata['day_of_due'] = nulldata['due_in_date'].dt.day\n",
    "nulldata['month_of_due'] = nulldata['due_in_date'].dt.month\n",
    "nulldata['year_of_due'] = nulldata['due_in_date'].dt.year\n",
    "\n",
    "nulldata['day_of_createdate'] = nulldata['baseline_create_date'].dt.day\n",
    "nulldata['month_of_createdate'] = nulldata['baseline_create_date'].dt.month\n",
    "nulldata['year_of_createdate'] = nulldata['baseline_create_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QeHWJYrAvOC6",
   "metadata": {
    "id": "QeHWJYrAvOC6"
   },
   "source": [
    "### Use Label Encoder1 of all the following columns - \n",
    "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
    "- 'business_code' and store into 'business_code_enc'\n",
    "- 'name_customer' and store into 'name_customer_enc'\n",
    "\n",
    "Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac330e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bac330e2",
    "outputId": "c47b529c-7674-4175-d8dc-db10614cfd81"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_payment_terms_enc']=label_encoder1.transform(nulldata['cust_payment_terms'])\n",
    "nulldata['business_code_enc']=label_encoder1.transform(nulldata['business_code'])\n",
    "nulldata['name_customer_enc']=label_encoder.transform(nulldata['name_customer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zD9I-XqQwC28",
   "metadata": {
    "id": "zD9I-XqQwC28"
   },
   "source": [
    "### Check for the datatypes of all the columns of Nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f72517",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4f72517",
    "outputId": "49681583-240d-4d2b-db3f-da0bd016def3"
   },
   "outputs": [],
   "source": [
    "nulldata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd5452",
   "metadata": {
    "id": "17cd5452"
   },
   "source": [
    "### Now you need to drop all the unnecessary columns - \n",
    "\n",
    "- 'business_code'\n",
    "- \"baseline_create_date\"\n",
    "- \"due_in_date\"\n",
    "- \"posting_date\"\n",
    "- \"name_customer\"\n",
    "- \"clear_date\"\n",
    "- \"cust_payment_terms\"\n",
    "- 'day_of_cleardate'\n",
    "- \"month_of_cleardate\"\n",
    "- \"year_of_cleardate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c82076",
   "metadata": {
    "id": "d7c82076"
   },
   "outputs": [],
   "source": [
    "nulldata=nulldata.drop(['business_code',\"baseline_create_date\",\"due_in_date\",\"posting_date\",\"name_customer\",\"clear_date\",\"cust_payment_terms\",'day_of_cleardate',\"month_of_cleardate\",\"year_of_cleardate\"],axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q_NCr9IPweVq",
   "metadata": {
    "id": "Q_NCr9IPweVq"
   },
   "source": [
    "### Check the information of the \"nulldata\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ffee0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e7ffee0",
    "outputId": "8e6e2c5a-965a-42d6-b104-0214e85c6d71"
   },
   "outputs": [],
   "source": [
    "nulldata.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-XvjhWqmwi-C",
   "metadata": {
    "id": "-XvjhWqmwi-C"
   },
   "source": [
    "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
    "\n",
    "- use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4b62d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02f4b62d",
    "outputId": "bb7c00bb-042a-4cfb-a727-509183d9bda8"
   },
   "outputs": [],
   "source": [
    "nulldata.info,X_test.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Us3ey-9zwqjq",
   "metadata": {
    "id": "Us3ey-9zwqjq"
   },
   "source": [
    "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
    "\n",
    "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vduVNt1kxPW-",
   "metadata": {
    "id": "vduVNt1kxPW-"
   },
   "source": [
    "- Display all the columns of the X_test dataframe \n",
    "- Display all the columns of the Nulldata dataframe \n",
    "- Store the Nulldata with new sequence into a new dataframe \n",
    "\n",
    "\n",
    "- Note - The code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729353e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6729353e",
    "outputId": "41d289e7-4e72-4c65-a71a-13d6aea9ca0e"
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd9c5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47bd9c5e",
    "outputId": "e71e8da3-5647-4ac2-86fa-ffdb3353b598"
   },
   "outputs": [],
   "source": [
    "nulldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a2103",
   "metadata": {
    "id": "aa5a2103"
   },
   "outputs": [],
   "source": [
    "nulldata2=nulldata[['cust_number', 'buisness_year', 'doc_id', 'converted_usd',\n",
    "       'business_code_enc', 'name_customer_enc', 'cust_payment_terms_enc',\n",
    "       'day_of_postingdate', 'month_of_postingdate', 'year_of_postingdate',\n",
    "       'day_of_createdate', 'month_of_createdate', 'year_of_createdate',\n",
    "       'day_of_due', 'month_of_due', 'year_of_due']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8b021",
   "metadata": {
    "id": "1dc8b021"
   },
   "source": [
    "### Display the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39785a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "2f39785a",
    "outputId": "c999346c-46f1-4e45-b5d4-fba275bcb463"
   },
   "outputs": [],
   "source": [
    "nulldata2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b88c5a",
   "metadata": {
    "id": "27b88c5a"
   },
   "source": [
    "### Now you can pass this dataset into you final model and store it into \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6388",
   "metadata": {
    "id": "9e0b6388"
   },
   "outputs": [],
   "source": [
    "final_result=regressorfinal.predict(nulldata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653d3c6",
   "metadata": {
    "id": "9653d3c6"
   },
   "source": [
    "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef814d",
   "metadata": {
    "id": "25ef814d"
   },
   "outputs": [],
   "source": [
    "final_result = pd.Series(final_result,name='avg_delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C86staIhyf2C",
   "metadata": {
    "id": "C86staIhyf2C"
   },
   "source": [
    "### Display the \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd46406",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fd46406",
    "outputId": "59b35e02-b4be-465b-fd9e-c5e69314edee"
   },
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame(final_result)\n",
    "final_result['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f71a7e",
   "metadata": {
    "id": "44f71a7e"
   },
   "source": [
    "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0969d",
   "metadata": {
    "id": "e8f0969d"
   },
   "outputs": [],
   "source": [
    "nulldata1.reset_index(drop=True,inplace=True)\n",
    "Final = nulldata1.merge(final_result , on = nulldata.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G-hLtxXgy4GZ",
   "metadata": {
    "id": "G-hLtxXgy4GZ"
   },
   "source": [
    "### Display the \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb4dc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "71fb4dc0",
    "outputId": "34faf08d-52db-423f-9d4e-d3cbf4953030"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sc27Uz-y-0O",
   "metadata": {
    "id": "4sc27Uz-y-0O"
   },
   "source": [
    "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5iUXOIhzy_HR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iUXOIhzy_HR",
    "outputId": "ef4a6918-ef31-4fa9-fcbd-f1503fd141ae"
   },
   "outputs": [],
   "source": [
    "Final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48886d2c",
   "metadata": {
    "id": "48886d2c"
   },
   "source": [
    "### Now, you need to do convert the below fields back into date and time format \n",
    "\n",
    "- Convert \"due_in_date\" into datetime format\n",
    "- Convert \"avg_delay\" into datetime format\n",
    "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
    "- display the new \"clear_date\" column\n",
    "- Note - Code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243abc2d",
   "metadata": {
    "id": "243abc2d"
   },
   "outputs": [],
   "source": [
    "Final['clear_date'] = pd.to_datetime(Final['due_in_date']) + pd.to_timedelta(Final['avg_delay'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9QcX_fAjIkYR",
   "metadata": {
    "id": "9QcX_fAjIkYR"
   },
   "source": [
    "### Display the \"clear_date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e1486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "740e1486",
    "outputId": "0541701b-7c8f-49b1-b9bc-33febf8190bc"
   },
   "outputs": [],
   "source": [
    "Final['clear_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MSkNLq6-z7rZ",
   "metadata": {
    "id": "MSkNLq6-z7rZ"
   },
   "source": [
    "### Convert the average delay into number of days format \n",
    "\n",
    "- Note - Formula = avg_delay//(24 * 3600)\n",
    "- Note - full code is given for this, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b618a",
   "metadata": {
    "id": "ce6b618a"
   },
   "outputs": [],
   "source": [
    "Final['avg_delay'] = Final.apply(lambda row: row.avg_delay//(24 * 3600), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wbBBZPjP0W7o",
   "metadata": {
    "id": "wbBBZPjP0W7o"
   },
   "source": [
    "### Display the \"avg_delay\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494982f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a494982f",
    "outputId": "245c3f68-5954-4515-8beb-7711e3b049d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d8811",
   "metadata": {
    "id": "815d8811"
   },
   "source": [
    "### Now you need to convert average delay column into bucket\n",
    "\n",
    "- Need to perform binning \n",
    "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
    "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "- perform binning by using cut() function from \"Final\" dataframe\n",
    "\n",
    "\n",
    "- Please fill up the first two rows of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797e4b5",
   "metadata": {
    "id": "c797e4b5"
   },
   "outputs": [],
   "source": [
    "\n",
    "bins= [0,15,30,45,60,100]\n",
    "labels =['0-15','16-30','31-45','46-60','Greater than 60']\n",
    "Final['Aging Bucket'] = pd.cut(Final['avg_delay'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35725f",
   "metadata": {
    "id": "1c35725f"
   },
   "source": [
    "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bc6a3",
   "metadata": {
    "id": "b31bc6a3"
   },
   "outputs": [],
   "source": [
    "Final=Final.drop(['key_0','avg_delay'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ui-tyIvU0-5u",
   "metadata": {
    "id": "Ui-tyIvU0-5u"
   },
   "source": [
    "### Display the count of each categoty of new \"Aging Bucket\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e16218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6e16218",
    "outputId": "aa60e9b2-e21b-4c7e-e70a-2cfd4efd90f3"
   },
   "outputs": [],
   "source": [
    "Final['Aging Bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kgYegy551GKJ",
   "metadata": {
    "id": "kgYegy551GKJ"
   },
   "source": [
    "### Display your final dataset with aging buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc87ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "c4bc87ec",
    "outputId": "c4d735f8-03cc-4fd4-c18c-e4c940516527"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ji7AoDCB1L_x",
   "metadata": {
    "id": "Ji7AoDCB1L_x"
   },
   "source": [
    "### Store this dataframe into the .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d0b8d",
   "metadata": {
    "id": "727d0b8d"
   },
   "outputs": [],
   "source": [
    "Final.to_csv('HRC60678WK_Debjyoti_Barman.csv',date_format='%Y/%m/%d',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FK0fabl61SkC",
   "metadata": {
    "id": "FK0fabl61SkC"
   },
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wcq6dWzy1ZR0",
    "0f2c8d02",
    "7abdb98b",
    "b8f63655",
    "ae724bfc",
    "110fa872",
    "968fbcc9",
    "65810f55",
    "154da511",
    "62633a84",
    "29310119",
    "G02cpnBhXJ14",
    "CsmScbHjYMv1",
    "LokxV2LGYUVh",
    "zz9kcrViYt7e",
    "eGcqS5EcY4BI",
    "dad18bb3",
    "AOzfgfeOZo3F",
    "eI6d49DQZrhW",
    "sbGXvBLQZw5E"
   ],
   "name": "HRC60678WK_Debjyoti_Barman_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
